{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhxPkX2qVJsU"
   },
   "source": [
    "# ED2 Santarem Job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBVezZ-RVLAJ"
   },
   "source": [
    "## Background\n",
    "\n",
    "The Ecosystem Demography Biosphere Model (ED2) is an integrated terrestrial biosphere model incorporating hydrology, land-surface biophysics, vegetation dynamics, and soil carbon and nitrogen biogeochemistry (Longo et al. 2019;Medvigy et al., 2009). Like its predecessor, ED (Moorcroft et al., 2001), ED2 uses a set of size- and age-structured partial differential equations that track the changing structure and composition of the plant canopy. With the ED2 model, in contrast to conventional biosphere models in which ecosystems with climatological grid cells are represented in a highly aggregated manner, the state of the aboveground ecosystem is described by the density of trees of different sizes and how this varies across horizontal space for a series of plant functional types. For more details, please go [here](https://github.com/EDmodel/*ED2*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhIyd63RGclK"
   },
   "source": [
    "## Run ED2 jobs on HPC cluster\n",
    "\n",
    "This notebook run ED2 jobs on HPC clusters. This currently works with servers that can be connected  via single-factor authentication. You can submit santarem job. There is a separate notebook for [other jobs.](https://colab.research.google.com/drive/1_b5t5P5UUpVDhXrhFjlT9aGces44nLSi#scrollTo=HjCnosfaFWET&uniqifier=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmhYpARjVfd1"
   },
   "source": [
    "## Prerequisites\n",
    "The following modules are necessary to run this notebook. Use pip install\n",
    "\n",
    "1. paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aDmEWk-Fu6U_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paramiko in /opt/conda/lib/python3.11/site-packages (3.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.11/site-packages (from paramiko) (4.1.2)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.11/site-packages (from paramiko) (41.0.4)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.11/site-packages (from paramiko) (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.3->paramiko) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Zf3NQL6UA0sc"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import paramiko\n",
    "import stat\n",
    "import os\n",
    "#from parsl.app.python import PythonApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D1Fgk_RVnJ4"
   },
   "source": [
    "## Server Details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "b9d-NgkZVogi"
   },
   "outputs": [],
   "source": [
    "# Cluster details\n",
    "hostname = 'login2.stampede2.tacc.utexas.edu' # the hostname of the cluster you want to run the ed2 model\n",
    "password = None\n",
    "username = \"ddey1\" # username on the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk5SPf-R8A9F"
   },
   "source": [
    "## Job output details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jHG7Vqj_8EKe"
   },
   "outputs": [],
   "source": [
    "show_status = False # Set this to see ocurrent status of the job you submitted\n",
    "show_output = False # Set this to see the output of the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulEj1ddhVrHV"
   },
   "source": [
    "## Batch job details\n",
    "Feel free to ignore the parameters if you wish to keep the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0yab3nnyVvZC"
   },
   "outputs": [],
   "source": [
    "# Batch job details\n",
    "time = \"0:04:00\"                        # Job run time (hh:mm:ss)\n",
    "nodes = 1                               # Number of nodes\n",
    "ntasks_per_node = 16                    # Number of task (cores/ppn) per node\n",
    "job_name = \"ED2IN-santarem\"             # Name of batch job\n",
    "partition = \"secondary\"                 # Partition (queue)\n",
    "output = \"openmp_\" + job_name + \".o%j\"  # Name of batch job output file\n",
    "error = \"openmp_\" + job_name + \".e%j\"   # Name of batch job error file\n",
    "mail_user = \"ABC@illinois.edu\"        # Send email notifications\n",
    "mail_type = \"BEGIN,END\"                 # Type of email notifications to send"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ls5SD_e9Gv4B"
   },
   "source": [
    "## Path to input data for job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ArVdnJqbBoTC"
   },
   "outputs": [],
   "source": [
    "# Path to various inputs\n",
    "path_to_data = \"${HOME}/ED-2.2_StartKit\" #path to data for ED2 on cluster\n",
    "path_to_singularity_image = \"${HOME}/ed2-intel.sif\" # path to singularity image of ED2 model on cluster\n",
    "path_to_ED2IN = \"Simulations/S0001_SantaremKm83_Test/ED2IN\" # path to ED2IN file on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ClX0zuppT1J9"
   },
   "outputs": [],
   "source": [
    "# Specific path changes required in Header and ED2IN file\n",
    "\n",
    "file_path_to_header_file =\"$HOME/ED-2.2_StartKit/ED2_InputData/SiteData/Santarem_Km83/MeteoDriver/Santarem_Km83_HEADER\" # path to header file\n",
    "pattern1 = \"path_to\" #pattern to replace in header file\n",
    "new_line1 = \"ED2_InputData/SiteData/Santarem_Km83/MeteoDriver/Santarem_Km83_\" # new line to be put in header file\n",
    "\n",
    "file_path_to_ED2IN = \"$HOME/ED-2.2_StartKit/Simulations/S0001_SantaremKm83_Test/ED2IN\"\n",
    "# FFILOUT -- Path and prefix for analysis files (all but history/restart).\n",
    "NLFFILOUT = \"/data/Simulations/S0001_SantaremKm83_Test/Analy/S0001_SantaremKm83_Test\"\n",
    "# SFILOUT -- Path and prefix for history files.\n",
    "NLSFILOUT = \"/data/Simulations/S0001_SantaremKm83_Test/Analy/S0001_SantaremKm83_Test\"\n",
    "# GFILOUT  -- Prefix for the output patch table/gap files\n",
    "NLGFILOUT = \"/data/Simulations/S0001_SantaremKm83_Test/Shade/S0001_SantaremKm83_Test\"\n",
    "# SFILIN --  The meaning and the size of this variable depends on the type of run, set  !\n",
    "NLSFILIN = \"/data/ED2_InputData/SiteData/Santarem_Km83/SiteBioData/s83_nounder.\"\n",
    "NLVEG_DATABASE = \"/data/ED2_InputData/GriddedData/VegetData/OGE2/OGE2_\"\n",
    "NLSOIL_DATABASE = \"/data/ED2_InputData/GriddedData/SoilData/Texture/SoilGrids20/SoilGrids20_\"\n",
    "NLLU_DATABASE = \"/data/ED2_InputData/GriddedData/LandUse/glu-3.3.1/glu-3.3.1-\"\n",
    "NLTHSUMS_DATABASE = \"/data/ED2_InputData/GriddedData/ThermalSums/\"\n",
    "NLED_MET_DRIVER_DB = \"/data/ED2_InputData/SiteData/Santarem_Km83/MeteoDriver/Santarem_Km83_HEADER\"\n",
    "NLSOILSTATE_DB = \"/data/ED2_InputData/GriddedData/SoilData/TempMoist/STW1996OCT.dat\"\n",
    "NLSOILDEPTH_DB = \"c\"\n",
    "\n",
    "# patterns to find and replce with new lines in ED2IN\n",
    "pattern2 = \"NL%FFILOUT\"\n",
    "new_line2 = \"NL%FFILOUT=\\\\'\" + NLFFILOUT + \"\\\\'\"\n",
    "pattern3 = \"NL%SFILOUT\"\n",
    "new_line3 = \"NL%SFILOUT=\\\\'\" + NLSFILOUT + \"\\\\'\"\n",
    "pattern4 = \"NL%GFILOUT\"\n",
    "new_line4 = \"NL%GFILOUT=\\\\'\" + NLGFILOUT + \"\\\\'\"\n",
    "pattern5 = \"NL%SFILIN\"\n",
    "new_line5 = \"NL%SFILIN=\\\\'\" + NLSFILIN + \"\\\\'\"\n",
    "pattern6 = \"NL%SFILIN\"\n",
    "new_line6 = \"NL%SFILIN=\\\\'\" + NLSFILIN + \"\\\\'\"\n",
    "pattern7=\"NL%VEG_DATABASE\"\n",
    "new_line7=\"NL%VEG_DATABASE=\\\\'\" + NLVEG_DATABASE + \"\\\\'\"\n",
    "pattern8=\"NL%SOIL_DATABASE\"\n",
    "new_line8=\"NL%SOIL_DATABASE=\\\\'\" + NLSOIL_DATABASE + \"\\\\'\"\n",
    "pattern9=\"NL%LU_DATABASE\"\n",
    "new_line9=\"NL%LU_DATABASE=\\\\'\" + NLLU_DATABASE + \"\\\\'\"\n",
    "pattern10=\"NL%THSUMS_DATABASE\"\n",
    "new_line10=\"NL%THSUMS_DATABASE=\\\\'\" + NLTHSUMS_DATABASE + \"\\\\'\"\n",
    "pattern11 =\"NL%ED_MET_DRIVER_DB\"\n",
    "new_line11 = \"NL%ED_MET_DRIVER_DB=\\\\'\" + NLED_MET_DRIVER_DB + \"\\\\'\"\n",
    "pattern12 = \"NL%ED_MET_DRIVER_DB\"\n",
    "new_line12 = \"NL%ED_MET_DRIVER_DB=\\\\'\" + NLED_MET_DRIVER_DB + \"\\\\'\"\n",
    "pattern13 = \"NL%SOILSTATE_DB\"\n",
    "new_line13 = \"NL%SOILSTATE_DB=\\\\'\" + NLSOILSTATE_DB + \"\\\\'\"\n",
    "pattern14 = \"NL%SOILDEPTH_DB\"\n",
    "new_line14 = \"NL%SOILDEPTH_DB=\\\\'\" + NLSOILDEPTH_DB + \"\\\\'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j6LbGTUR-XB",
    "outputId": "ad3d5926-8130-4649-a4a1-b2af42b34c07"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n",
      " ········\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m     ssh_client\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     99\u001b[0m     transport\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 101\u001b[0m \u001b[43msubmit_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 61\u001b[0m, in \u001b[0;36msubmit_job\u001b[0;34m(username)\u001b[0m\n\u001b[1;32m     58\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#transfer .bat file to cluster and run it\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43msftp_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.sbatch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43musername\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.sbatch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m sftp_client\u001b[38;5;241m.\u001b[39mchmod(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musername\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m job_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.sbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, stat\u001b[38;5;241m.\u001b[39mS_IRWXU)\n\u001b[1;32m     63\u001b[0m _, stdo, stde \u001b[38;5;241m=\u001b[39m ssh_client\u001b[38;5;241m.\u001b[39mexec_command(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msbatch \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m job_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.sbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/paramiko/sftp_client.py:759\u001b[0m, in \u001b[0;36mSFTPClient.put\u001b[0;34m(self, localpath, remotepath, callback, confirm)\u001b[0m\n\u001b[1;32m    757\u001b[0m file_size \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(localpath)\u001b[38;5;241m.\u001b[39mst_size\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(localpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fl:\n\u001b[0;32m--> 759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mputfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremotepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfirm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/paramiko/sftp_client.py:714\u001b[0m, in \u001b[0;36mSFTPClient.putfo\u001b[0;34m(self, fl, remotepath, file_size, callback, confirm)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mputfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, fl, remotepath, file_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, confirm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    688\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    Copy the contents of an open file object (``fl``) to the SFTP server as\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    ``remotepath``. Any exception raised by operations will be passed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.10\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremotepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fr:\n\u001b[1;32m    715\u001b[0m         fr\u001b[38;5;241m.\u001b[39mset_pipelined(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    716\u001b[0m         size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_with_callback(\n\u001b[1;32m    717\u001b[0m             reader\u001b[38;5;241m=\u001b[39mfl, writer\u001b[38;5;241m=\u001b[39mfr, file_size\u001b[38;5;241m=\u001b[39mfile_size, callback\u001b[38;5;241m=\u001b[39mcallback\n\u001b[1;32m    718\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/paramiko/sftp_client.py:372\u001b[0m, in \u001b[0;36mSFTPClient.open\u001b[0;34m(self, filename, mode, bufsize)\u001b[0m\n\u001b[1;32m    370\u001b[0m     imode \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m SFTP_FLAG_CREATE \u001b[38;5;241m|\u001b[39m SFTP_FLAG_EXCL\n\u001b[1;32m    371\u001b[0m attrblock \u001b[38;5;241m=\u001b[39m SFTPAttributes()\n\u001b[0;32m--> 372\u001b[0m t, msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCMD_OPEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m!=\u001b[39m CMD_HANDLE:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SFTPError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected handle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/paramiko/sftp_client.py:857\u001b[0m, in \u001b[0;36mSFTPClient._request\u001b[0;34m(self, t, *args)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    856\u001b[0m     num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_request(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), t, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/paramiko/sftp_client.py:909\u001b[0m, in \u001b[0;36mSFTPClient._read_response\u001b[0;34m(self, waitfor)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num \u001b[38;5;241m==\u001b[39m waitfor:\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# synchronous\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m CMD_STATUS:\n\u001b[0;32m--> 909\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t, msg\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# can not rewrite this to deal with E721, either as a None check\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;66;03m# nor as not an instance of None or NoneType\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/paramiko/sftp_client.py:938\u001b[0m, in \u001b[0;36mSFTPClient._convert_status\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(text)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m SFTP_NO_SUCH_FILE:\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;66;03m# clever idea from john a. meinel: map the error codes to errno\u001b[39;00m\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mENOENT, text)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m SFTP_PERMISSION_DENIED:\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEACCES, text)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file"
     ]
    }
   ],
   "source": [
    "def run_singularity(executable, singularity_image, args, stdout=None, stderr=None):\n",
    "    return f\"{executable} exec {singularity_image} {args}\"\n",
    "\n",
    "# Function for custom interactive handler when you try to login into HPC cluster\n",
    "def auth_interactive_handler_callback(title, instructions, prompts):\n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        prompt_text = prompt[0]\n",
    "        echo = prompt[1]\n",
    "        response = getpass.getpass(prompt_text) if echo else getpass.getpass('')\n",
    "        responses.append(response)\n",
    "    return responses\n",
    "\n",
    "def submit_job(username):\n",
    "    ssh_client = paramiko.SSHClient()\n",
    "    ssh_client.load_system_host_keys()\n",
    "    ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    try:\n",
    "        ssh_client.connect(hostname, username=username, password=password, allow_agent=True)\n",
    "        print(\"successfully connected\")\n",
    "    except:\n",
    "        pass\n",
    "    transport = ssh_client.get_transport()\n",
    "    #transport.auth_password(username, getpass.getpass('Enter {0} Logon password :'.format(hostname)))\n",
    "    transport.auth_interactive(username=username, handler=auth_interactive_handler_callback)\n",
    "    sftp_client = paramiko.SFTPClient.from_transport(transport)\n",
    "\n",
    "\n",
    "    #create the bat file\n",
    "    with open(job_name + \".sbatch\", 'w') as f:\n",
    "        f.writelines(\"#!/bin/bash\\n\")\n",
    "        f.writelines(\"#SBATCH --time=\" + str(time) + \"\\n\")\n",
    "        f.writelines(\"#SBATCH --ntasks-per-node=\" + str(ntasks_per_node) + \"\\n\")\n",
    "        f.writelines(\"#SBATCH --job-name=\" + job_name + \"\\n\")\n",
    "        f.writelines(\"#SBATCH --partition=\" + partition + \"\\n\")\n",
    "        f.writelines(\"#SBATCH --output=\" + output + \"\\n\")\n",
    "        f.writelines(\"#SBATCH --error=\" + error + \"\\n\")\n",
    "        f.writelines(\"#SBATCH --mail-user=\" + mail_user + \"\\n\")\n",
    "        f.writelines(\"#SBATCH --mail-type=\" + mail_type + \"\\n\")\n",
    "        f.writelines(\"\\n\")\n",
    "        f.writelines(\"module load singularity\" + \"\\n\")\n",
    "        #f.writeline(\"sed -i '/pattern1/c$new_line1\" \"$file_path_to_header_file\"\" + \"\\n\")\n",
    "        f.writelines([f\"sed -i /{pattern1}/c{new_line1} {file_path_to_header_file}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern2}/c{new_line2} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern3}/c{new_line3} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern4}/c{new_line4} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern5}/c{new_line5} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern6}/c{new_line6} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern7}/c{new_line7} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern8}/c{new_line8} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern9}/c{new_line9} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern10}/c{new_line10} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern11}/c{new_line11} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern12}/c{new_line12} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern13}/c{new_line13} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines([f\"sed -i /{pattern14}/c{new_line14} {file_path_to_ED2IN}\\n\"])\n",
    "        f.writelines(\"singularity exec --bind \" + path_to_data + \":/data --no-home --pwd /data \" + path_to_singularity_image + \" ed2 -f \" + path_to_ED2IN)\n",
    "    f.close()\n",
    "\n",
    "    #transfer .bat file to cluster and run it\n",
    "    sftp_client.put(job_name + \".sbatch\", f\"/home/{username}/\" + job_name + \".sbatch\")\n",
    "    sftp_client.chmod(f\"/home/{username}/\" + job_name + \".sbatch\", stat.S_IRWXU)\n",
    "    _, stdo, stde = ssh_client.exec_command(\"sbatch \" + job_name + \".sbatch\")\n",
    "    print(stde.read().decode())\n",
    "\n",
    "    # Extract the job ID from the sbatch output\n",
    "    result = stdo.read().decode()\n",
    "    print(result)\n",
    "    job_id = result.split()[3]\n",
    "\n",
    "    # Show job status\n",
    "    if show_status:\n",
    "        # Check the job status periodically\n",
    "        while True:\n",
    "            #job_status = subprocess.run(f\"squeue -u {username} -j {job_id}\", shell=True, capture_output=True, text=True)\n",
    "            _, stdo, stde = ssh_client.exec_command(f\"squeue -u {username} -j {job_id}\")\n",
    "            job_status = stdo.read().decode()\n",
    "            print(job_status)\n",
    "\n",
    "            # Break the loop if the job is completed or failed\n",
    "            if job_id not in job_status:\n",
    "                break\n",
    "\n",
    "            # Wait for a few seconds before checking again\n",
    "            timer.sleep(10)\n",
    "    if show_output:\n",
    "        print(\"Output\")\n",
    "        # View output\n",
    "        _, stdo, stde = ssh_client.exec_command(f\"cat /home/{username}/openmp_{job_name}.o{job_id}\")\n",
    "        print(stdo.read().decode())\n",
    "\n",
    "        print(\"Error\")\n",
    "        # View error\n",
    "        _, stdo, stde = ssh_client.exec_command(f\"cat /home/{username}/openmp_{job_name}.e{job_id}\")\n",
    "        print(stdo.read().decode())\n",
    "\n",
    "    sftp_client.close()\n",
    "    ssh_client.close()\n",
    "    transport.close()\n",
    "\n",
    "submit_job(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
