{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ED2 Santarem Job\n"
      ],
      "metadata": {
        "id": "MhxPkX2qVJsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background\n",
        "\n",
        "The Ecosystem Demography Biosphere Model (ED2) is an integrated terrestrial biosphere model incorporating hydrology, land-surface biophysics, vegetation dynamics, and soil carbon and nitrogen biogeochemistry (Longo et al. 2019;Medvigy et al., 2009). Like its predecessor, ED (Moorcroft et al., 2001), ED2 uses a set of size- and age-structured partial differential equations that track the changing structure and composition of the plant canopy. With the ED2 model, in contrast to conventional biosphere models in which ecosystems with climatological grid cells are represented in a highly aggregated manner, the state of the aboveground ecosystem is described by the density of trees of different sizes and how this varies across horizontal space for a series of plant functional types. For more details, please go [here](https://github.com/EDmodel/*ED2*)."
      ],
      "metadata": {
        "id": "jBVezZ-RVLAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run ED2 jobs on HPC cluster\n",
        "\n",
        "This notebook run ED2 jobs on HPC clusters. This currently works with servers that can be connected  via single-factor authentication. You can submit santarem job. There is a separate notebook for [other jobs.](https://colab.research.google.com/drive/1_b5t5P5UUpVDhXrhFjlT9aGces44nLSi#scrollTo=HjCnosfaFWET&uniqifier=2)"
      ],
      "metadata": {
        "id": "IhIyd63RGclK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "The following modules are necessary to run this notebook. Use pip install\n",
        "\n",
        "1. paramiko"
      ],
      "metadata": {
        "id": "bmhYpARjVfd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paramiko"
      ],
      "metadata": {
        "id": "aDmEWk-Fu6U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import paramiko\n",
        "import stat\n",
        "import os\n",
        "#from parsl.app.python import PythonApp"
      ],
      "metadata": {
        "id": "Zf3NQL6UA0sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server Details\n"
      ],
      "metadata": {
        "id": "7D1Fgk_RVnJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster details\n",
        "hostname = 'cc-login.campuscluster.illinois.edu' # the hostname of the cluster you want to run the ed2 model\n",
        "password = None\n",
        "username = \"ABC\" # username on the cluster"
      ],
      "metadata": {
        "id": "b9d-NgkZVogi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Job output details"
      ],
      "metadata": {
        "id": "Gk5SPf-R8A9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_status = False # Set this to see ocurrent status of the job you submitted\n",
        "show_output = False # Set this to see the output of the job"
      ],
      "metadata": {
        "id": "jHG7Vqj_8EKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch job details\n",
        "Feel free to ignore the parameters if you wish to keep the default."
      ],
      "metadata": {
        "id": "ulEj1ddhVrHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch job details\n",
        "time = \"0:04:00\"                        # Job run time (hh:mm:ss)\n",
        "nodes = 1                               # Number of nodes\n",
        "ntasks_per_node = 16                    # Number of task (cores/ppn) per node\n",
        "job_name = \"ED2IN-santarem\"             # Name of batch job\n",
        "partition = \"secondary\"                 # Partition (queue)\n",
        "output = \"openmp_\" + job_name + \".o%j\"  # Name of batch job output file\n",
        "error = \"openmp_\" + job_name + \".e%j\"   # Name of batch job error file\n",
        "mail_user = \"ABC@illinois.edu\"        # Send email notifications\n",
        "mail_type = \"BEGIN,END\"                 # Type of email notifications to send"
      ],
      "metadata": {
        "id": "0yab3nnyVvZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Path to input data for job"
      ],
      "metadata": {
        "id": "Ls5SD_e9Gv4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to various inputs\n",
        "path_to_data = \"${HOME}/ED-2.2_StartKit\" #path to data for ED2 on cluster\n",
        "path_to_singularity_image = \"${HOME}/ed2-intel.sif\" # path to singularity image of ED2 model on cluster\n",
        "path_to_ED2IN = \"Simulations/S0001_SantaremKm83_Test/ED2IN\" # path to ED2IN file on cluster"
      ],
      "metadata": {
        "id": "ArVdnJqbBoTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specific path changes required in Header and ED2IN file\n",
        "\n",
        "file_path_to_header_file =\"$HOME/ED-2.2_StartKit/ED2_InputData/SiteData/Santarem_Km83/MeteoDriver/Santarem_Km83_HEADER\" # path to header file\n",
        "pattern1 = \"path_to\" #pattern to replace in header file\n",
        "new_line1 = \"ED2_InputData/SiteData/Santarem_Km83/MeteoDriver/Santarem_Km83_\" # new line to be put in header file\n",
        "\n",
        "file_path_to_ED2IN = \"$HOME/ED-2.2_StartKit/Simulations/S0001_SantaremKm83_Test/ED2IN\"\n",
        "# FFILOUT -- Path and prefix for analysis files (all but history/restart).\n",
        "NLFFILOUT = \"/data/Simulations/S0001_SantaremKm83_Test/Analy/S0001_SantaremKm83_Test\"\n",
        "# SFILOUT -- Path and prefix for history files.\n",
        "NLSFILOUT = \"/data/Simulations/S0001_SantaremKm83_Test/Analy/S0001_SantaremKm83_Test\"\n",
        "# GFILOUT  -- Prefix for the output patch table/gap files\n",
        "NLGFILOUT = \"/data/Simulations/S0001_SantaremKm83_Test/Shade/S0001_SantaremKm83_Test\"\n",
        "# SFILIN --  The meaning and the size of this variable depends on the type of run, set  !\n",
        "NLSFILIN = \"/data/ED2_InputData/SiteData/Santarem_Km83/SiteBioData/s83_nounder.\"\n",
        "NLVEG_DATABASE = \"/data/ED2_InputData/GriddedData/VegetData/OGE2/OGE2_\"\n",
        "NLSOIL_DATABASE = \"/data/ED2_InputData/GriddedData/SoilData/Texture/SoilGrids20/SoilGrids20_\"\n",
        "NLLU_DATABASE = \"/data/ED2_InputData/GriddedData/LandUse/glu-3.3.1/glu-3.3.1-\"\n",
        "NLTHSUMS_DATABASE = \"/data/ED2_InputData/GriddedData/ThermalSums/\"\n",
        "NLED_MET_DRIVER_DB = \"/data/ED2_InputData/SiteData/Santarem_Km83/MeteoDriver/Santarem_Km83_HEADER\"\n",
        "NLSOILSTATE_DB = \"/data/ED2_InputData/GriddedData/SoilData/TempMoist/STW1996OCT.dat\"\n",
        "NLSOILDEPTH_DB = \"c\"\n",
        "\n",
        "# patterns to find and replce with new lines in ED2IN\n",
        "pattern2 = \"NL%FFILOUT\"\n",
        "new_line2 = \"NL%FFILOUT=\\\\'\" + NLFFILOUT + \"\\\\'\"\n",
        "pattern3 = \"NL%SFILOUT\"\n",
        "new_line3 = \"NL%SFILOUT=\\\\'\" + NLSFILOUT + \"\\\\'\"\n",
        "pattern4 = \"NL%GFILOUT\"\n",
        "new_line4 = \"NL%GFILOUT=\\\\'\" + NLGFILOUT + \"\\\\'\"\n",
        "pattern5 = \"NL%SFILIN\"\n",
        "new_line5 = \"NL%SFILIN=\\\\'\" + NLSFILIN + \"\\\\'\"\n",
        "pattern6 = \"NL%SFILIN\"\n",
        "new_line6 = \"NL%SFILIN=\\\\'\" + NLSFILIN + \"\\\\'\"\n",
        "pattern7=\"NL%VEG_DATABASE\"\n",
        "new_line7=\"NL%VEG_DATABASE=\\\\'\" + NLVEG_DATABASE + \"\\\\'\"\n",
        "pattern8=\"NL%SOIL_DATABASE\"\n",
        "new_line8=\"NL%SOIL_DATABASE=\\\\'\" + NLSOIL_DATABASE + \"\\\\'\"\n",
        "pattern9=\"NL%LU_DATABASE\"\n",
        "new_line9=\"NL%LU_DATABASE=\\\\'\" + NLLU_DATABASE + \"\\\\'\"\n",
        "pattern10=\"NL%THSUMS_DATABASE\"\n",
        "new_line10=\"NL%THSUMS_DATABASE=\\\\'\" + NLTHSUMS_DATABASE + \"\\\\'\"\n",
        "pattern11 =\"NL%ED_MET_DRIVER_DB\"\n",
        "new_line11 = \"NL%ED_MET_DRIVER_DB=\\\\'\" + NLED_MET_DRIVER_DB + \"\\\\'\"\n",
        "pattern12 = \"NL%ED_MET_DRIVER_DB\"\n",
        "new_line12 = \"NL%ED_MET_DRIVER_DB=\\\\'\" + NLED_MET_DRIVER_DB + \"\\\\'\"\n",
        "pattern13 = \"NL%SOILSTATE_DB\"\n",
        "new_line13 = \"NL%SOILSTATE_DB=\\\\'\" + NLSOILSTATE_DB + \"\\\\'\"\n",
        "pattern14 = \"NL%SOILDEPTH_DB\"\n",
        "new_line14 = \"NL%SOILDEPTH_DB=\\\\'\" + NLSOILDEPTH_DB + \"\\\\'\""
      ],
      "metadata": {
        "id": "ClX0zuppT1J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j6LbGTUR-XB",
        "outputId": "ad3d5926-8130-4649-a4a1-b2af42b34c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter cc-login.campuscluster.illinois.edu Logon password :··········\n",
            "Submitted batch job 9863129\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def run_singularity(executable, singularity_image, args, stdout=None, stderr=None):\n",
        "    return f\"{executable} exec {singularity_image} {args}\"\n",
        "\n",
        "def submit_job(username):\n",
        "    ssh_client = paramiko.SSHClient()\n",
        "    ssh_client.load_system_host_keys()\n",
        "    ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
        "    try:\n",
        "        ssh_client.connect(hostname, username=username, password=password, allow_agent=True)\n",
        "        print(\"successfully connected\")\n",
        "    except:\n",
        "        pass\n",
        "    transport = ssh_client.get_transport()\n",
        "    transport.auth_password(username, getpass.getpass('Enter {0} Logon password :'.format(hostname)))\n",
        "    sftp_client = paramiko.SFTPClient.from_transport(transport)\n",
        "\n",
        "\n",
        "    #create the bat file\n",
        "    with open(job_name + \".sbatch\", 'w') as f:\n",
        "        f.writelines(\"#!/bin/bash\\n\")\n",
        "        f.writelines(\"#SBATCH --time=\" + str(time) + \"\\n\")\n",
        "        f.writelines(\"#SBATCH --ntasks-per-node=\" + str(ntasks_per_node) + \"\\n\")\n",
        "        f.writelines(\"#SBATCH --job-name=\" + job_name + \"\\n\")\n",
        "        f.writelines(\"#SBATCH --partition=\" + partition + \"\\n\")\n",
        "        f.writelines(\"#SBATCH --output=\" + output + \"\\n\")\n",
        "        f.writelines(\"#SBATCH --error=\" + error + \"\\n\")\n",
        "        f.writelines(\"#SBATCH --mail-user=\" + mail_user + \"\\n\")\n",
        "        f.writelines(\"#SBATCH --mail-type=\" + mail_type + \"\\n\")\n",
        "        f.writelines(\"\\n\")\n",
        "        f.writelines(\"module load singularity\" + \"\\n\")\n",
        "        #f.writeline(\"sed -i '/pattern1/c$new_line1\" \"$file_path_to_header_file\"\" + \"\\n\")\n",
        "        f.writelines([f\"sed -i /{pattern1}/c{new_line1} {file_path_to_header_file}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern2}/c{new_line2} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern3}/c{new_line3} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern4}/c{new_line4} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern5}/c{new_line5} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern6}/c{new_line6} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern7}/c{new_line7} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern8}/c{new_line8} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern9}/c{new_line9} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern10}/c{new_line10} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern11}/c{new_line11} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern12}/c{new_line12} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern13}/c{new_line13} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines([f\"sed -i /{pattern14}/c{new_line14} {file_path_to_ED2IN}\\n\"])\n",
        "        f.writelines(\"singularity exec --bind \" + path_to_data + \":/data --no-home --pwd /data \" + path_to_singularity_image + \" ed2 -f \" + path_to_ED2IN)\n",
        "    f.close()\n",
        "\n",
        "    #transfer .bat file to cluster and run it\n",
        "    sftp_client.put(job_name + \".sbatch\", f\"/home/{username}/\" + job_name + \".sbatch\")\n",
        "    sftp_client.chmod(f\"/home/{username}/\" + job_name + \".sbatch\", stat.S_IRWXU)\n",
        "    _, stdo, stde = ssh_client.exec_command(\"sbatch \" + job_name + \".sbatch\")\n",
        "    print(stde.read().decode())\n",
        "\n",
        "    # Extract the job ID from the sbatch output\n",
        "    result = stdo.read().decode()\n",
        "    print(result)\n",
        "    job_id = result.split()[3]\n",
        "\n",
        "    # Show job status\n",
        "    if show_status:\n",
        "        # Check the job status periodically\n",
        "        while True:\n",
        "            #job_status = subprocess.run(f\"squeue -u {username} -j {job_id}\", shell=True, capture_output=True, text=True)\n",
        "            _, stdo, stde = ssh_client.exec_command(f\"squeue -u {username} -j {job_id}\")\n",
        "            job_status = stdo.read().decode()\n",
        "            print(job_status)\n",
        "\n",
        "            # Break the loop if the job is completed or failed\n",
        "            if job_id not in job_status:\n",
        "                break\n",
        "\n",
        "            # Wait for a few seconds before checking again\n",
        "            timer.sleep(10)\n",
        "    if show_output:\n",
        "        print(\"Output\")\n",
        "        # View output\n",
        "        _, stdo, stde = ssh_client.exec_command(f\"cat /home/{username}/openmp_{job_name}.o{job_id}\")\n",
        "        print(stdo.read().decode())\n",
        "\n",
        "        print(\"Error\")\n",
        "        # View error\n",
        "        _, stdo, stde = ssh_client.exec_command(f\"cat /home/{username}/openmp_{job_name}.e{job_id}\")\n",
        "        print(stdo.read().decode())\n",
        "\n",
        "    sftp_client.close()\n",
        "    ssh_client.close()\n",
        "    transport.close()\n",
        "\n",
        "submit_job(username)"
      ]
    }
  ]
}